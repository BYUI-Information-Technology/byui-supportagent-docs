---
title: "What is RAG?"
description: "An accessible explanation of Retrieval Augmented Generation (RAG) for BYU-Idaho staff involved in knowledge content creation and curation for AI systems."
---

## Overview

**Retrieval Augmented Generation (RAG)** is a technique that enhances AI systems by giving them access to specific, trusted knowledge sources—like the documentation you create—so they can provide accurate, contextual answers to questions.

Think of RAG as giving an AI assistant a well-organized reference library before answering questions, rather than relying solely on its general training.

## Who Invented RAG?

In 2020, Facebook (now Meta) invented a technique called [Retrieval Augmented Generation (RAG)](https://arxiv.org/abs/2005.11401) to improve the accuracy of AI models for domain-specific tasks like question answering for support agents. RAG works by augmenting the AI model's knowledge with external sources of information, such as a knowledge base or a database. This allows the AI model to answer questions with more accuracy and precision. Engineers at BYU-Idaho have employed this technique to enable the Support Agent to answer questions about BYU-Idaho. The image below illustrates how RAG works for the Support Agent.

## Why RAG Matters at BYU-Idaho

RAG enables our AI systems to:

- Answer questions using _department's specific policies and procedures_
- Provide accurate information about _BYU-Idaho systems and processes_
- Reference _current, maintained documentation_ rather than outdated information
- Cite sources and show exactly where information came from

## How RAG Works (Simplified)

RAG has three main steps:

### 1. Retrieval

When someone asks a question, the AI system, like the BYUI Support Agent, searches through the knowledge base to find the most relevant documentation. This search uses:

- **Semantic understanding** - Finding documents by _meaning_, not just keyword matching
- **Metadata filtering** - Using the fields you provide (`tags`, `department`, `status`) to narrow results
- **Recency signals** - Prioritizing up-to-date content based on your `last_updated` field

### 2. Augmentation

The AI system takes the relevant documentation it found and adds it as context to the user's question. Instead of answering from memory alone, it now has your curated knowledge to work with.

### 3. Generation

The AI generates a response using both its general capabilities _and_ the specific knowledge you provided. This results in answers that are:

- Grounded in official BYU-Idaho documentation
- Accurate to your department's current processes
- Traceable back to authoritative sources

## The Role of Vector Storage

To make semantic search possible, documentation is converted into mathematical representations called _vectors_ (think of them as numerical "fingerprints" of meaning). These vectors are stored in BYU-Idaho's enterprise vector database: **Pinecone**.

> [!NOTE] BYU-Idaho uses **Pinecone** as our vector database platform. When your Markdown documents are ingested, they're automatically converted to vectors and stored in Pinecone, making them searchable by our AI agents.

When someone asks a question, Pinecone quickly finds the documentation that's most semantically similar to their question—even if they use different words than you did in the documentation.

## Practical Example

**Scenario:** A student asks the Support Agent, "How do I register for fall classes?"

**Without RAG:** The AI answers based on general knowledge about college registration, which may be inaccurate or outdated.

**With RAG:**

1. The system searches Pinecone for documentation matching "fall class registration 2025"
2. It retrieves knowledge base articles which are ranked and score by confidence levels (example: 90%)
3. It uses just those articles to generate an accurate, BYU-Idaho-specific answer
4. It provides the source information for the articles

The knowledge base _directly powers_ the LLM responses.

## RAG vs. Traditional AI

| Traditional AI (No RAG)           | RAG-Enhanced AI                                                |
| --------------------------------- | -------------------------------------------------------------- |
| Answers from training data only   | Answers from training data + knowledge base                    |
| May be outdated or generic        | Current and institution-specific                               |
| No source citations               | Can cite specific documents                                    |
| Can't access new information      | Updated whenever vector database is synced with knowledge base |
| Limited to what it was trained on | Extensible with the content in the knowledge base              |

## Key Takeaways

- **RAG connects AI to real documentation** - The knowledge base becomes the AI's "knowledge"
- **BYU-Idaho uses Pinecone** - Our enterprise vector database that makes semantic search possible
- **Knowledge base quality impacts AI accuracy** - Well-curated content leads to trustworthy AI responses and reduced hallucination