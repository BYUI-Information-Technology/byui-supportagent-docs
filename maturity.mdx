---
title: "Institutional AI Maturity"
description: "Thoughts to consider as we approach conversations regarding adoption, ethics, and concerns regarding artificial intelligence"
---

Dario Amodei, CEO of [Anthropic](https://www.anthropic.com/company), recently published an essay called "[The Adolescence of Technology](https://www.darioamodei.com/essay/the-adolescence-of-technology)." His central metaphor is striking: humanity is gaining extraordinary power before developing the wisdom to wield it. Like a teenager with a sports car, we have capability without commensurate judgment.

This framing resonates uncomfortably well with our current moment in higher education. AI has arrived on our campuses, and we're not sure what to do with it. Some faculty have embraced it enthusiastically. Others have restricted it entirely. And a significant number are simply hoping the whole thing blows over.

I want to suggest that much of our disagreement stems not from different values, but from different fears. And if we can name those fears honestly, we might find that the path forward requires elements from multiple perspectives—not a victory of one camp over another.

## Three Camps, Three Fears

Across campus, I've observed three distinct postures toward AI in academics. Each is responding to something real. Each has legitimate concerns. And each, taken alone, is incomplete.

<Card title="The Three Camps" img="/images/three-ai-camps.png">
  
</Card>

|                             | **Dismissive**                                                                                                                                                                                                                                          | **Accelerationist**                                                                                                                                                                                                                           | **Doomer**                                                                                                                                                                                                                                                                                         |
| --------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Core belief**             | This is overhyped. It's not my problem. I'll wait and see.                                                                                                                                                                                              | AI is transforming every industry. Our students will graduate into a world where AI fluency is as fundamental as computer literacy was a generation ago. We must prepare them—now.                                                            | AI is undermining the integrity of education itself. Students are skipping the learning process. Our assessments are broken. We're graduating people who haven't actually learned what their transcripts claim.                                                                                    |
| **The fear**                | Overwhelm. The pace of change is exhausting, and engaging with AI means rethinking courses, assessments, and pedagogy that took years to develop. It's easier to not engage.                                                                            | If we move too slowly, we'll send students into the job market unprepared. Other institutions will out-innovate us. Our graduates will be at a disadvantage. We're already behind.                                                            | We're in a crisis of verification and formation. The foundational skills that education is supposed to build—critical thinking, writing, problem-solving, intellectual struggle—are being bypassed. If we don't protect the learning process, we'll produce credentialed but incapable graduates.  |
| **What they're protecting** | Sanity. Stability. The hope that maybe this will settle down and someone else will figure it out.                                                                                                                                                       | Student employability. Institutional relevance. Our mission to prepare students for meaningful work.                                                                                                                                          | The learning process itself. Institutional credibility. The meaning of a BYU-Idaho degree. The formative struggle that makes education transformative rather than transactional.                                                                                                                   |
| **Typical posture**         | Minimal policy. No discussion in syllabus. Business as usual. Hope students don't notice either.                                                                                                                                                        | Make AI integration a university-wide priority. Train faculty. Embed AI across the curriculum. Move faster.                                                                                                                                   | Restrict or ban AI, especially in foundational courses. Return to in-person assessment. Protect the fundamentals before it's too late.                                                                                                                                                             |
| **The valid concern**       | Faculty are already stretched thin. Not every new technology deserves a full institutional response. Skepticism about hype cycles is often warranted.                                                                                                   | A student who graduates in without AI fluency will be competing against candidates who have it. The job market won't wait for us to figure this out.                                                                                          | A student who uses AI to write their first college essay has bypassed something important. There's a reason we don't give calculators to kids learning arithmetic. And if employers lose trust that our graduates actually possess the skills we've certified, our degrees become worthless paper. |
| **The risk**                | Disengagement isn't neutral. Students are using AI whether we engage or not. The dismissive posture cedes the conversation entirely—to students figuring it out alone, to other institutions moving faster, to a future where we're caught flat-footed. | Speed without wisdom produces the adolescence problem Amodei warns about. Students who can prompt but can't think. Capability without judgment. Powerful tools in the hands of people who haven't developed the discernment to use them well. | Restriction alone doesn't prepare students for the world they'll actually inhabit. And if the posture becomes primarily defensive—alarm without agency—it can slide into paralysis or institutional retreat from a challenge we need to face.                                                      |

## Why All Three Are Incomplete

Here's what I've come to believe: each of these positions is responding to a genuine threat. They're not wrong—they're partial.

- The **Dismissive** camp is right that not every hype cycle deserves panic. But disengagement is a choice with consequences.
- The **Accelerationist** camp is right that preparation matters and the world is changing fast. But speed without wisdom produces exactly the adolescence problem.
- The **Doomer** camp is right that foundational learning and institutional credibility must be protected. But restriction without a path forward produces irrelevance.

The problem is that each camp, pursued alone, creates the failure mode the other camps fear:

| If we only... | We risk...                                                                          |
| ------------- | ----------------------------------------------------------------------------------- |
| Disengage     | Being blindsided; students left to figure it out alone; institutional irrelevance   |
| Accelerate    | Graduating students who can use tools but can't think independently                 |
| Restrict      | Graduating students unprepared for the actual world; losing the real benefits of AI |

This is the adolescence problem applied to institutions: we have powerful new capabilities, and each of our instinctive responses is inadequate to the moment.

## The Mature Position: Capability AND Judgment

What would institutional maturity look like? Not a mushy compromise that satisfies no one, but a genuine synthesis that takes each concern seriously.

<Steps>
  <Step title="Engagement is non-negotiable">
    The dismissive position is understandable but untenable. AI is not a fad that will blow over. It's a fundamental shift in how knowledge work happens. We don't have to panic, but we do have to engage. This doesn't mean every faculty member needs to become an AI expert. It means we can't collectively pretend this isn't happening.
  </Step>
  <Step title="Sequence matters more than permission">
    The question isn't "Should students use AI?" but "When in their development, and for what purposes?" A first-year student writing their first argumentative essay needs to wrestle with constructing an argument from scratch. A senior preparing a professional deliverable needs to know how to leverage AI effectively. Both are appropriate to their developmental stage. This suggests we need _curricular intentionality_—not blanket policies, but thoughtful sequencing of when AI assists and when it's set aside. The doomer concern about protecting foundational learning is valid; the answer is developmental scaffolding, not permanent restriction.
  </Step>
  <Step title="Assessment must evolve, not just policies">
    If our assessments can be completed by AI, they were probably measuring the wrong things anyway. The doomer camp is right that this is urgent—but the response isn't only to restrict AI. It's to redesign assessment around what we actually care about: understanding, judgment, and the ability to do something meaningful with knowledge. This might mean more oral examinations, process portfolios, in-class demonstrations, and collaborative projects where AI use is transparent and evaluated as a skill rather than treated as cheating.
  </Step>
  <Step title="AI fluency is a new literacy, not a shortcut">
    We should teach students to use AI the way we teach them to use libraries, databases, and citation systems—as tools that require skill, judgment, and ethical awareness. This is not "letting students cheat." It's preparing them to be wise users of powerful tools—which is exactly what the accelerationist camp wants, done responsibly.
  </Step>
  <Step title="The discipleship dimension">
    Discipleship has always required both capability and character, both skill and wisdom. The adolescence problem—power without maturity—is precisely what discipleship formation is designed to address. We've been doing this work for generations, just not with AI. The question for us isn't merely "How do we handle AI in academics?" It's "How do we develop disciples of Christ, future leaders who can wield powerful tools with wisdom, integrity, and service to others?" That's a question we're responsible to answer.
  </Step>
</Steps>

## Toward Action: What This Might Mean

If we take the mature position seriously, several implications follow:

**For individual faculty:**

- Engage, even if cautiously. Disengagement isn't neutral.
- Be explicit with students about your expectations and reasoning—they're navigating this too.
- Experiment in low-stakes ways. You don't have to revolutionize your pedagogy overnight.

**For curriculum design:**

- Map AI use expectations across the student journey, from restricted in foundational courses to expected in capstone work
- Identify which skills in each discipline must be developed without AI assistance, and protect those deliberately
- Build AI literacy into the curriculum as a learnable skill, not an assumed capability

**For assessment:**

- Audit current assessments for AI vulnerability—not to catch cheaters, but to identify what needs redesign
- Invest in assessment approaches that measure understanding and application, not just output
- Consider program-level verification milestones (e.g., oral examinations, portfolio defenses) that provide assurance of actual capability

**For institutional posture:**

- Resist both the urge to ignore and the urge to panic
- Communicate to students that we're taking this seriously—neither dismissing AI nor capitulating to it
- Position BYU-Idaho as a place that produces graduates who are both AI-capable AND deeply formed as learners and disciples

## An Invitation

We're not going to resolve this in a single forum, a single semester, or a single policy. AI is not a problem to be solved but a condition to be navigated—and navigated together. Let's start building from our shared commitments. We all want students who can think. We all want graduates who are prepared. We all want credentials that mean something. We all want to fulfill our mission.

The mature position isn't a lukewarm compromise. It's harder than any single camp because it requires holding multiple concerns simultaneously while moving forward deliberately.

But that's what maturity requires.

---

[_This article draws on Dario Amodei's essay "The Adolescence of Technology"_](https://www.darioamodei.com/essay/the-adolescence-of-technology)